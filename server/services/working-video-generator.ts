/**
 * Working Video Generator - A functional implementation focusing on what works
 */

import ffmpeg from 'fluent-ffmpeg';
import { join } from 'path';
import { v4 as uuidv4 } from 'uuid';
import { mkdir, writeFile, readFile, unlink } from 'fs/promises';
import OpenAI from 'openai';
import Replicate from 'replicate';
// Skip ElevenLabs for now since package needs migration
import axios from 'axios';
import path from 'path';
import fs from 'fs';

interface VideoJob {
  id: string;
  prompt: string;
  duration: number;
  status: string;
  progress: number;
  currentStep: string;
  script?: any;
  images?: string[];
  videos?: string[];
  audio?: string;
  finalVideo?: string;
}

export class WorkingVideoGenerator {
  private outputDir: string;
  private openai: OpenAI;
  private replicate: Replicate;
  // private elevenlabs: ElevenLabsClient;

  constructor() {
    this.outputDir = join(process.cwd(), 'media', 'generated');
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
    this.replicate = new Replicate({
      auth: process.env.REPLICATE_API_TOKEN,
    });
    // this.elevenlabs = new ElevenLabsClient({
    //   apiKey: process.env.ELEVENLABS_API_KEY,
    // });
  }

  private async ensureOutputDirectory() {
    try {
      await mkdir(this.outputDir, { recursive: true });
    } catch (error) {
      // Directory might already exist
    }
  }

  async generateWorkingVideo(job: VideoJob): Promise<string> {
    await this.ensureOutputDirectory();

    try {
      // Step 1: Generate script (this works)
      console.log('[WORKING] Step 1: Generating script...');
      job.currentStep = 'Generating script...';
      job.progress = 10;
      const script = await this.generateScript(job.prompt, job.duration);
      job.script = script;

      // Step 2: Create simple colored frames (instead of complex image generation)
      console.log('[WORKING] Step 2: Creating video frames...');
      job.currentStep = 'Creating video frames...';
      job.progress = 30;
      const videoPath = await this.createColoredVideo(script, job.duration);

      // Step 3: Generate voiceover
      console.log('[WORKING] Step 3: Generating voiceover...');
      job.currentStep = 'Generating voiceover...';
      job.progress = 50;
      const audioPath = await this.generateVoiceover(script.narration || script.description);

      // Step 4: Combine video and audio
      console.log('[WORKING] Step 4: Combining video and audio...');
      job.currentStep = 'Combining video and audio...';
      job.progress = 80;
      const finalPath = await this.combineVideoAudio(videoPath, audioPath);

      job.finalVideo = finalPath;
      job.status = 'completed';
      job.progress = 100;
      job.currentStep = 'Video generation complete!';

      return finalPath;

    } catch (error) {
      console.error('[WORKING] Generation failed:', error);
      job.status = 'failed';
      job.currentStep = `Failed: ${error.message}`;
      throw error;
    }
  }

  private async generateScript(prompt: string, duration: number): Promise<any> {
    try {
      const completion = await this.openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          {
            role: "system",
            content: `You are a video script writer. Create a script for a ${duration}-second video. 
                     Return JSON with these fields:
                     - title: A catchy title
                     - description: Brief description
                     - narration: The voiceover text (should be spoken in ${duration} seconds)
                     - scenes: Array of 3-5 scene descriptions`
          },
          {
            role: "user",
            content: prompt
          }
        ],
        response_format: { type: "json_object" },
        temperature: 0.8,
      });

      return JSON.parse(completion.choices[0].message.content || '{}');
    } catch (error) {
      console.error('[WORKING] Script generation error:', error);
      // Fallback script
      return {
        title: "AI Generated Video",
        description: prompt,
        narration: `This is a video about ${prompt}. It showcases the power of AI video generation.`,
        scenes: [
          { description: "Opening scene with title" },
          { description: "Main content showcase" },
          { description: "Closing with call to action" }
        ]
      };
    }
  }

  private async createColoredVideo(script: any, duration: number): Promise<string> {
    const outputPath = join(this.outputDir, `video_${uuidv4()}.mp4`);
    
    try {
      console.log('[WORKING] Generating scene images with SDXL...');
      
      // Generate images for each scene
      const images = [];
      const scenes = script.scenes || [script.description];
      
      for (let i = 0; i < Math.min(scenes.length, 5); i++) {
        const sceneText = typeof scenes[i] === 'string' ? scenes[i] : scenes[i].description;
        console.log(`[WORKING] Generating image ${i + 1}/${scenes.length}: ${sceneText}`);
        
        try {
          // Check if Replicate API key exists
          if (!process.env.REPLICATE_API_TOKEN) {
            console.warn('[WORKING] Replicate API token not found, skipping image generation');
            images.push(null);
            continue;
          }
          
          // Use Replicate SDXL to generate images
          console.log(`[WORKING] Calling Replicate API for scene ${i + 1}...`);
          const output = await this.replicate.run(
            "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
            {
              input: {
                prompt: sceneText + ", cinematic, high quality, 8k, photorealistic, professional",
                negative_prompt: "worst quality, low quality, blurry, watermark, text, yellow",
                width: 1024,
                height: 576,
                num_outputs: 1,
                guidance_scale: 7.5,
                num_inference_steps: 30
              }
            }
          );
          
          if (output && output[0]) {
            console.log(`[WORKING] Successfully generated image URL: ${output[0]}`);
            images.push(output[0]);
          } else {
            console.log(`[WORKING] No output from Replicate for scene ${i + 1}`);
            images.push(null);
          }
        } catch (error) {
          console.error(`[WORKING] Failed to generate image ${i + 1}:`, error.message || error);
          console.error(`[WORKING] Full error:`, error);
          images.push(null);
        }
      }
      
      // Log what we got from image generation
      console.log('[WORKING] Image generation results:', images);
      console.log('[WORKING] Valid images count:', images.filter(img => img !== null).length);
      
      // Create video from images if we have any
      if (images.some(img => img !== null) && images.filter(img => img !== null).length > 0) {
        const imagePaths = [];
        
        // Download images
        for (let i = 0; i < images.length; i++) {
          if (images[i]) {
            const imagePath = join(this.outputDir, `scene_${i}_${uuidv4()}.jpg`);
            try {
              const response = await fetch(images[i]);
              const buffer = await response.arrayBuffer();
              await writeFile(imagePath, Buffer.from(buffer));
              imagePaths.push(imagePath);
              console.log(`[WORKING] Downloaded image ${i + 1} to:`, imagePath);
            } catch (error) {
              console.error(`[WORKING] Failed to download image ${i}:`, error);
            }
          }
        }
        
        if (imagePaths.length > 0) {
          // Professional video creation from AI-generated images with advanced effects
          console.log('[WORKING] Creating professional video with AI images and advanced effects...');
          const frameDuration = duration / imagePaths.length;
          
          return new Promise((resolve, reject) => {
            const ffmpegCommand = ffmpeg();
            
            // Add each image as input with professional loop settings
            imagePaths.forEach((imagePath, index) => {
              ffmpegCommand
                .input(imagePath)
                .inputOptions([
                  '-loop', '1',
                  '-t', frameDuration.toString(),
                  '-framerate', '30'
                ]);
            });
            
            // Professional filter complex with transitions, scaling, and effects
            const filterParts = [];
            
            // Scale and add ken burns effect to each image
            imagePaths.forEach((_, index) => {
              filterParts.push(
                `[${index}:v]scale=1920:1080:force_original_aspect_ratio=increase,crop=1920:1080,` +
                `zoompan=z='if(lte(zoom,1.0),1.5,max(1.001,zoom-0.0015))':d=${Math.floor(frameDuration * 30)}:s=1920x1080:fps=30[v${index}]`
              );
            });
            
            // Add fade transitions between scenes
            if (imagePaths.length > 1) {
              let transitionChain = '[v0]';
              for (let i = 1; i < imagePaths.length; i++) {
                const fadeStart = frameDuration * i - 0.5;
                const fadeDuration = 1.0;
                transitionChain += `[v${i}]xfade=transition=fade:duration=${fadeDuration}:offset=${fadeStart}`;
                if (i < imagePaths.length - 1) {
                  transitionChain += `[vt${i}];[vt${i}]`;
                } else {
                  transitionChain += '[vfinal]';
                }
              }
              filterParts.push(transitionChain);
            } else {
              filterParts.push('[v0]copy[vfinal]');
            }
            
            // Add professional color grading and film look
            filterParts.push(
              '[vfinal]eq=contrast=1.1:brightness=0.05:saturation=1.15,curves=all=\'0/0 0.25/0.22 0.5/0.55 0.75/0.78 1/1\',vignette=a=PI/4[vcol]'
            );
            
            // Add title overlay with professional styling
            const title = script.title || 'AI Generated Video';
            const titleEscaped = title.replace(/'/g, "\\'").replace(/:/g, "\\:");
            filterParts.push(
              `[vcol]drawtext=text='${titleEscaped}':fontsize=72:fontcolor=white:x=(w-text_w)/2:y=100:` +
              `box=1:boxcolor=black@0.6:boxborderw=8:enable='between(t,1,${duration-1})'[vtitle]`
            );
            
            // Add subtle animated overlay effects
            filterParts.push(
              '[vtitle]drawtext=text=\'VeeFore AI\':fontsize=32:fontcolor=white@0.8:x=w-text_w-50:y=h-60:' +
              `box=1:boxcolor=black@0.4:boxborderw=4:enable='between(t,2,${duration-0.5})'[vout]`
            );
            
            const filterComplex = filterParts.join(';');
            
            ffmpegCommand
              .complexFilter(filterComplex)
              .outputOptions([
                '-map', '[vout]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'medium',
                '-crf', '20',
                '-profile:v', 'high',
                '-level', '4.0',
                '-movflags', '+faststart'
              ])
              .output(outputPath)
              .on('start', (cmd) => {
                console.log('[WORKING] Creating professional video with advanced effects...');
                console.log('[WORKING] FFmpeg command:', cmd.substring(0, 200) + '...');
              })
              .on('progress', (progress) => {
                if (progress.percent) {
                  console.log(`[WORKING] Video processing: ${Math.round(progress.percent)}%`);
                }
              })
              .on('end', async () => {
                console.log('[WORKING] Professional video created successfully from AI images:', outputPath);
                
                // Clean up image files
                for (const imagePath of imagePaths) {
                  try {
                    await unlink(imagePath);
                  } catch (error) {
                    // Ignore cleanup errors
                  }
                }
                
                resolve(outputPath);
              })
              .on('error', (err) => {
                console.error('[WORKING] Professional video creation error:', err);
                reject(err);
              });
            
            ffmpegCommand.run();
          });
        }
      }
      
      // Fallback to gradient video with animated text overlay
      console.log('[WORKING] Creating fallback video with gradient and animated text...');
      return new Promise((resolve, reject) => {
        const title = script.title || 'AI Generated Video';
        const description = script.description || prompt;
        const titleEscaped = title.replace(/'/g, "\\'").replace(/:/g, "\\:");
        const descEscaped = description.replace(/'/g, "\\'").replace(/:/g, "\\:");
        
        // Create a simple colored video with text overlay
        const command = ffmpeg()
          .input(`color=c=blue:s=1920x1080:d=${duration}`)
          .inputFormat('lavfi')
          .videoFilters([
            `drawtext=text='${titleEscaped}':fontsize=80:fontcolor=white:x=(w-text_w)/2:y=h/3:box=1:boxcolor=black@0.8:boxborderw=10`,
            `drawtext=text='VeeFore AI Video':fontsize=40:fontcolor=white:x=(w-text_w)/2:y=h-200:box=1:boxcolor=black@0.8:boxborderw=5`
          ])
          .outputOptions([
            '-c:v', 'libx264',
            '-pix_fmt', 'yuv420p',
            '-preset', 'fast',
            '-crf', '23'
          ])
          .output(outputPath)
          .on('start', (cmd) => {
            console.log('[WORKING] Creating gradient video...');
          })
          .on('end', () => {
            console.log('[WORKING] Gradient video created successfully:', outputPath);
            resolve(outputPath);
          })
          .on('error', (err) => {
            console.error('[WORKING] Gradient video failed, trying simpler approach:', err.message);
            
            // Ultra simple fallback - just colored rectangles with text
            const simpleCommand = ffmpeg();
            
            // Create simple colored video with static text
            simpleCommand
              .input('lavfi')
              .inputOptions([
                '-f', 'lavfi',
                '-i', `testsrc2=duration=${duration}:size=1920x1080:rate=30`
              ])
              .videoFilters([
                'drawbox=x=0:y=0:w=1920:h=1080:c=0x2563EB:t=fill',
                `drawtext=text='${titleEscaped}':fontsize=72:fontcolor=white:x=(w-text_w)/2:y=(h-text_h)/2:box=1:boxcolor=black:boxborderw=5`
              ])
              .outputOptions([
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'ultrafast',
                '-crf', '28'
              ])
              .output(outputPath)
              .on('end', () => {
                console.log('[WORKING] Simple colored video created successfully');
                resolve(outputPath);
              })
              .on('error', (simpleErr) => {
                console.error('[WORKING] All video generation attempts failed:', simpleErr);
                reject(simpleErr);
              })
              .run();
          });

        command.run();
      });
      
    } catch (error) {
      console.error('[WORKING] Video creation error:', error);
      throw new Error(`Failed to create video: ${error.message}`);
    }
  }

  private async generateVoiceover(text: string): Promise<string> {
    const outputPath = join(this.outputDir, `audio_${uuidv4()}.mp3`);
    
    try {
      console.log('[WORKING] Generating voiceover with ElevenLabs for text:', text.substring(0, 50) + '...');
      
      // Use ElevenLabs API to generate voiceover
      const apiKey = process.env.ELEVENLABS_API_KEY;
      if (!apiKey) {
        console.warn('[WORKING] ElevenLabs API key not found, falling back to silent audio');
        return this.createSilentAudio(outputPath, 10);
      }
      
      // Use Rachel voice (professional female voice)
      const voiceId = '21m00Tcm4TlvDq8ikWAM';
      
      const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
        method: 'POST',
        headers: {
          'xi-api-key': apiKey,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text: text,
          model_id: 'eleven_monolingual_v1',
          voice_settings: {
            stability: 0.75,
            similarity_boost: 0.75,
            style: 0.5,
            use_speaker_boost: true
          }
        })
      });
      
      if (!response.ok) {
        const error = await response.text();
        console.error('[WORKING] ElevenLabs API error:', error);
        throw new Error(`ElevenLabs API error: ${response.status}`);
      }
      
      // Save the audio file
      const audioBuffer = await response.arrayBuffer();
      await writeFile(outputPath, Buffer.from(audioBuffer));
      
      console.log('[WORKING] Voiceover generated successfully with ElevenLabs:', outputPath);
      return outputPath;
      
    } catch (error) {
      console.error('[WORKING] Voiceover generation failed:', error);
      console.log('[WORKING] Falling back to silent audio');
      // Create silent audio as fallback
      return this.createSilentAudio(outputPath, 10);
    }
  }

  private async createSilentAudio(outputPath: string, duration: number): Promise<string> {
    return new Promise((resolve, reject) => {
      ffmpeg()
        .input('anullsrc=r=44100:cl=stereo')
        .inputFormat('lavfi')
        .duration(duration)
        .outputOptions(['-acodec', 'libmp3lame'])
        .output(outputPath)
        .on('end', () => {
          console.log('[WORKING] Silent audio created');
          resolve(outputPath);
        })
        .on('error', reject)
        .run();
    });
  }

  private async combineVideoAudio(videoPath: string, audioPath: string): Promise<string> {
    const outputPath = join(this.outputDir, `final_${uuidv4()}.mp4`);
    
    return new Promise((resolve, reject) => {
      const command = ffmpeg()
        .input(videoPath)
        .input(audioPath)
        .outputOptions([
          '-c:v copy',
          '-c:a aac',
          '-shortest' // Match duration to shortest input
        ])
        .output(outputPath)
        .on('start', (cmd) => {
          console.log('[WORKING] Combining video and audio...');
        })
        .on('end', () => {
          console.log('[WORKING] Final video created:', outputPath);
          resolve(outputPath);
        })
        .on('error', (err) => {
          console.error('[WORKING] Combination error:', err);
          // If combination fails, just return the video without audio
          resolve(videoPath);
        });

      command.run();
    });
  }
}